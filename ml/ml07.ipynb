{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-20T15:12:21.918242Z",
     "start_time": "2024-10-20T15:12:18.896678Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from geopy.distance import geodesic\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from datetime import datetime\n",
    "\n",
    "# Load datasets\n",
    "vessel_data = pd.read_csv('../ais_train.csv', sep='|')\n",
    "schedule_data = pd.read_csv('../schedules_to_may_2024.csv', sep='|')\n",
    "ports_data = pd.read_csv('../ports.csv', sep='|')\n",
    "vessels_info = pd.read_csv('../vessels.csv', sep='|')\n",
    "\n",
    "# Step 1: Convert 'time' column to datetime in vessel_data\n",
    "vessel_data['time'] = pd.to_datetime(vessel_data['time'])\n",
    "\n",
    "# Feature extraction: Create time-based features\n",
    "vessel_data['hour'] = vessel_data['time'].dt.hour\n",
    "vessel_data['day_of_week'] = vessel_data['time'].dt.dayofweek\n",
    "vessel_data['month'] = vessel_data['time'].dt.month"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T15:12:23.183502Z",
     "start_time": "2024-10-20T15:12:21.921755Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Step 2: Calculate sailing velocity (distance between positions divided by time difference)\n",
    "# Ensure that lag features are computed for each vessel separately\n",
    "vessel_data = vessel_data.sort_values(['vesselId', 'time'])  # Sort by vessel and time\n",
    "vessel_data['prev_latitude'] = vessel_data.groupby('vesselId')['latitude'].shift(1)\n",
    "vessel_data['prev_longitude'] = vessel_data.groupby('vesselId')['longitude'].shift(1)\n",
    "vessel_data['prev_time'] = vessel_data.groupby('vesselId')['time'].shift(1)"
   ],
   "id": "2d28c10464e6d05f",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T15:12:23.250138Z",
     "start_time": "2024-10-20T15:12:23.213702Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Compute time difference in hours\n",
    "vessel_data['time_diff'] = (vessel_data['time'] - vessel_data['prev_time']).dt.total_seconds() / 3600"
   ],
   "id": "f3ddc34b021e23b4",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T15:15:19.145869Z",
     "start_time": "2024-10-20T15:12:23.281677Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Calculate the distance traveled (in kilometers)\n",
    "vessel_data['distance_traveled'] = vessel_data.apply(\n",
    "    lambda row: geodesic(\n",
    "        (row['prev_latitude'], row['prev_longitude']), \n",
    "        (row['latitude'], row['longitude'])\n",
    "    ).kilometers if pd.notnull(row['prev_latitude']) else np.nan, axis=1)"
   ],
   "id": "85fc5f9afbc1d651",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T15:15:19.202728Z",
     "start_time": "2024-10-20T15:15:19.192432Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Calculate sailing velocity (km/h)\n",
    "vessel_data['sailing_velocity'] = vessel_data['distance_traveled'] / vessel_data['time_diff']"
   ],
   "id": "9b5be1d6dea13ce1",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T15:15:19.870511Z",
     "start_time": "2024-10-20T15:15:19.237890Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Step 3: Merge with vessels_info\n",
    "# Ensure unique vessel information is merged without duplicating rows\n",
    "vessel_data = pd.merge(vessel_data, vessels_info[['vesselId', 'CEU', 'length', 'maxSpeed']], on='vesselId', how='left')\n",
    "\n",
    "# Step 4: Merge with ports_data\n",
    "# Merge on 'portId' carefully to avoid many-to-many issues\n",
    "vessel_data = pd.merge(vessel_data, ports_data[['portId', 'latitude', 'longitude']], left_on='portId', right_on='portId', how='left', suffixes=('', '_port'))"
   ],
   "id": "9c49e50d47c26d66",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T15:18:40.869860Z",
     "start_time": "2024-10-20T15:15:20.105377Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Calculate the distance to the nearest port (or the destination port)\n",
    "vessel_data['distance_to_port'] = vessel_data.apply(\n",
    "    lambda row: geodesic(\n",
    "        (row['latitude'], row['longitude']), \n",
    "        (row['latitude_port'], row['longitude_port'])\n",
    "    ).kilometers if pd.notnull(row['latitude_port']) else np.nan, axis=1)"
   ],
   "id": "17733fac9b715d9f",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T15:18:41.311336Z",
     "start_time": "2024-10-20T15:18:41.109883Z"
    }
   },
   "cell_type": "code",
   "source": "print(vessel_data)",
   "id": "712ed3db9e2b8f5a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       time    cog   sog  rot  heading  navstat       etaRaw  \\\n",
      "0       2024-01-12 14:07:47  308.1  17.1   -6      316        0  01-08 06:00   \n",
      "1       2024-01-12 14:31:00  307.6  17.3    5      313        0  01-14 23:30   \n",
      "2       2024-01-12 14:57:23  306.8  16.9    5      312        0  01-14 23:30   \n",
      "3       2024-01-12 15:18:48  307.9  16.9    6      313        0  01-14 23:30   \n",
      "4       2024-01-12 15:39:47  307.0  16.3    7      313        0  01-14 23:30   \n",
      "...                     ...    ...   ...  ...      ...      ...          ...   \n",
      "1522060 2024-05-07 22:36:16  324.1  13.5   -2      325        0  05-08 03:00   \n",
      "1522061 2024-05-07 22:57:05  324.2  13.3   -3      326        0  05-08 03:00   \n",
      "1522062 2024-05-07 23:17:54  356.5  12.2   -1      354        0  05-08 03:00   \n",
      "1522063 2024-05-07 23:38:13   52.6  17.3    3       50        0  05-08 03:00   \n",
      "1522064 2024-05-07 23:59:01   53.6  17.7   -1       51        0  05-08 03:00   \n",
      "\n",
      "         latitude  longitude                   vesselId  ...  \\\n",
      "0         7.50361   77.58340   61e9f38eb937134a3c4bfd8b  ...   \n",
      "1         7.57302   77.49505   61e9f38eb937134a3c4bfd8b  ...   \n",
      "2         7.65043   77.39404   61e9f38eb937134a3c4bfd8b  ...   \n",
      "3         7.71275   77.31394   61e9f38eb937134a3c4bfd8b  ...   \n",
      "4         7.77191   77.23585   61e9f38eb937134a3c4bfd8b  ...   \n",
      "...           ...        ...                        ...  ...   \n",
      "1522060  59.63337   21.43237  clh6aqawa0007gh0z9h6zi9bo  ...   \n",
      "1522061  59.69588   21.34225  clh6aqawa0007gh0z9h6zi9bo  ...   \n",
      "1522062  59.76388   21.35317  clh6aqawa0007gh0z9h6zi9bo  ...   \n",
      "1522063  59.83316   21.38489  clh6aqawa0007gh0z9h6zi9bo  ...   \n",
      "1522064  59.89167   21.54685  clh6aqawa0007gh0z9h6zi9bo  ...   \n",
      "\n",
      "                  prev_time  time_diff  distance_traveled  sailing_velocity  \\\n",
      "0                       NaT        NaN                NaN               NaN   \n",
      "1       2024-01-12 14:07:47   0.386944          12.409686         32.070976   \n",
      "2       2024-01-12 14:31:00   0.439722          14.054327         31.961831   \n",
      "3       2024-01-12 14:57:23   0.356944          11.207092         31.397302   \n",
      "4       2024-01-12 15:18:48   0.349722          10.817233         30.930927   \n",
      "...                     ...        ...                ...               ...   \n",
      "1522060 2024-05-07 22:15:17   0.349722           8.757636         25.041690   \n",
      "1522061 2024-05-07 22:36:16   0.346944           8.619686         24.844571   \n",
      "1522062 2024-05-07 22:57:05   0.346944           7.600588         21.907218   \n",
      "1522063 2024-05-07 23:17:54   0.338611           7.921160         23.393088   \n",
      "1522064 2024-05-07 23:38:13   0.346667          11.173414         32.231003   \n",
      "\n",
      "          CEU  length maxSpeed  latitude_port  longitude_port  \\\n",
      "0        6500   199.0     18.6      13.263333       80.341111   \n",
      "1        6500   199.0     18.6      18.941944       72.885278   \n",
      "2        6500   199.0     18.6      18.941944       72.885278   \n",
      "3        6500   199.0     18.6      18.941944       72.885278   \n",
      "4        6500   199.0     18.6      18.941944       72.885278   \n",
      "...       ...     ...      ...            ...             ...   \n",
      "1522060   200   191.0      NaN      60.437778       22.216389   \n",
      "1522061   200   191.0      NaN      60.437778       22.216389   \n",
      "1522062   200   191.0      NaN      60.437778       22.216389   \n",
      "1522063   200   191.0      NaN      60.437778       22.216389   \n",
      "1522064   200   191.0      NaN      60.437778       22.216389   \n",
      "\n",
      "         distance_to_port  \n",
      "0              704.981193  \n",
      "1             1353.034007  \n",
      "2             1341.043850  \n",
      "3             1331.466560  \n",
      "4             1322.318699  \n",
      "...                   ...  \n",
      "1522060         99.706885  \n",
      "1522061         95.924332  \n",
      "1522062         89.123341  \n",
      "1522063         81.686863  \n",
      "1522064         71.301410  \n",
      "\n",
      "[1522065 rows x 26 columns]\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T15:18:42.037322Z",
     "start_time": "2024-10-20T15:18:41.533262Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Step 5: Merge with schedule_data\n",
    "\n",
    "# Check for duplicates in schedule_data for vesselId\n",
    "duplicate_schedule = schedule_data[schedule_data.duplicated('vesselId', keep=False)]\n",
    "\n",
    "# If duplicates exist, select only the latest or earliest arrival date for each vessel\n",
    "schedule_data_unique = schedule_data.sort_values(by='arrivalDate').drop_duplicates('vesselId', keep='last')\n",
    "\n",
    "# Convert arrivalDate to datetime, ensuring it's timezone-naive\n",
    "schedule_data_unique['arrivalDate'] = pd.to_datetime(schedule_data_unique['arrivalDate']).dt.tz_localize(None)\n",
    "\n",
    "# Merge vessel_data with the unique schedule_data\n",
    "vessel_data = pd.merge(vessel_data, schedule_data_unique[['vesselId', 'arrivalDate']], on='vesselId', how='left')\n",
    "\n",
    "# Ensure that vessel_data['time'] is timezone-naive\n",
    "vessel_data['time'] = vessel_data['time'].dt.tz_localize(None)\n",
    "\n",
    "# Create the time until scheduled arrival feature\n",
    "vessel_data['time_until_arrival'] = (vessel_data['arrivalDate'] - vessel_data['time']).dt.total_seconds() / 3600  # Time in hours"
   ],
   "id": "5775efab358eed84",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T15:18:44.512047Z",
     "start_time": "2024-10-20T15:18:42.282283Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Step 6: Drop unnecessary columns or duplicates if needed\n",
    "vessel_data = vessel_data.drop_duplicates()"
   ],
   "id": "dd0f0186cd0d3d3d",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T15:18:55.199555Z",
     "start_time": "2024-10-20T15:18:44.722624Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Prepare the dataset for training\n",
    "X = vessel_data[['hour', 'day_of_week', 'month', 'sailing_velocity', 'CEU', 'length', 'maxSpeed', 'distance_to_port', 'time_until_arrival']]\n",
    "y_latitude = vessel_data['latitude']  # Target for latitude\n",
    "y_longitude = vessel_data['longitude']  # Target for longitude\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train_lat, X_test_lat, y_train_lat, y_test_lat = train_test_split(X, y_latitude, test_size=0.2, random_state=42)\n",
    "X_train_lon, X_test_lon, y_train_lon, y_test_lon = train_test_split(X, y_longitude, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model for latitude prediction\n",
    "model_latitude = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=100, learning_rate=0.1)\n",
    "model_latitude.fit(X_train_lat, y_train_lat)\n",
    "\n",
    "# Make predictions on the test set for latitude\n",
    "y_pred_latitude = model_latitude.predict(X_test_lat)\n",
    "\n",
    "# Evaluate the latitude model\n",
    "mse_latitude = mean_squared_error(y_test_lat, y_pred_latitude)\n",
    "r2_latitude = r2_score(y_test_lat, y_pred_latitude)\n",
    "\n",
    "print(f'Mean Squared Error (Latitude): {mse_latitude}')\n",
    "print(f'R-squared (Latitude): {r2_latitude}')\n",
    "\n",
    "# Train the model for longitude prediction\n",
    "model_longitude = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=100, learning_rate=0.1)\n",
    "model_longitude.fit(X_train_lon, y_train_lon)\n",
    "\n",
    "# Make predictions on the test set for longitude\n",
    "y_pred_longitude = model_longitude.predict(X_test_lon)\n",
    "\n",
    "# Evaluate the longitude model\n",
    "mse_longitude = mean_squared_error(y_test_lon, y_pred_longitude)\n",
    "r2_longitude = r2_score(y_test_lon, y_pred_longitude)\n",
    "\n",
    "print(f'Mean Squared Error (Longitude): {mse_longitude}')\n",
    "print(f'R-squared (Longitude): {r2_longitude}')"
   ],
   "id": "1d4c81f1228d85f4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (Latitude): 223.39886129231058\n",
      "R-squared (Latitude): 0.5749278862648384\n",
      "Mean Squared Error (Longitude): 2462.0760602182004\n",
      "R-squared (Longitude): 0.4794367412804249\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T15:24:37.633961Z",
     "start_time": "2024-10-20T15:24:31.139691Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Prepare the dataset for training with limited features (same as test set)\n",
    "X_limited = vessel_data[['hour', 'day_of_week', 'month']]\n",
    "y_latitude = vessel_data['latitude']  # Target for latitude\n",
    "y_longitude = vessel_data['longitude']  # Target for longitude\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train_lat, X_test_lat, y_train_lat, y_test_lat = train_test_split(X_limited, y_latitude, test_size=0.2, random_state=42)\n",
    "X_train_lon, X_test_lon, y_train_lon, y_test_lon = train_test_split(X_limited, y_longitude, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model for latitude prediction\n",
    "model_latitude = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=100, learning_rate=0.1)\n",
    "model_latitude.fit(X_train_lat, y_train_lat)\n",
    "\n",
    "# Train the model for longitude prediction\n",
    "model_longitude = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=100, learning_rate=0.1)\n",
    "model_longitude.fit(X_train_lon, y_train_lon)\n",
    "\n",
    "# Load the test data and make sure to only extract the available features (hour, day_of_week, month)\n",
    "ais_test = pd.read_csv('../ais_test.csv', sep=',')\n",
    "\n",
    "# Convert 'time' column to datetime in test data\n",
    "ais_test['time'] = pd.to_datetime(ais_test['time'])\n",
    "\n",
    "# Create time-based features for test data\n",
    "ais_test['hour'] = ais_test['time'].dt.hour\n",
    "ais_test['day_of_week'] = ais_test['time'].dt.dayofweek\n",
    "ais_test['month'] = ais_test['time'].dt.month\n",
    "\n",
    "# Select features for prediction\n",
    "X_test_limited = ais_test[['hour', 'day_of_week', 'month']]\n",
    "\n",
    "# Make predictions for latitude and longitude using the model trained with limited features\n",
    "latitude_predictions = model_latitude.predict(X_test_limited)\n",
    "longitude_predictions = model_longitude.predict(X_test_limited)\n",
    "\n",
    "# Load the sample submission file\n",
    "sample_submission = pd.read_csv('../ais_sample_submission.csv')\n",
    "\n",
    "# Fill in the predicted latitude and longitude\n",
    "sample_submission['latitude_predicted'] = latitude_predictions\n",
    "sample_submission['longitude_predicted'] = longitude_predictions\n",
    "\n",
    "# Save the filled submission file\n",
    "sample_submission.to_csv('submission02.csv', index=False)\n",
    "\n",
    "# Display the first few rows of the submission file to verify\n",
    "print(sample_submission.head())\n"
   ],
   "id": "8c66a1756ebeb5d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ID  longitude_predicted  latitude_predicted\n",
      "0   0            10.714623           37.924057\n",
      "1   1            10.714623           37.924057\n",
      "2   2            10.714623           37.924057\n",
      "3   3            10.714623           37.924057\n",
      "4   4            10.714623           37.924057\n"
     ]
    }
   ],
   "execution_count": 23
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
